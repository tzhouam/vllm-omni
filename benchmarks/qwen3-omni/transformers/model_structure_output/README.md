# Qwen3 Omni 30B æ¨¡å‹æ¶æ„æ–‡æ¡£

å®Œæ•´çš„ Qwen3 Omni 30B æ¨¡å‹æ¶æ„å¯è§†åŒ–å’Œåˆ†ææ–‡æ¡£ã€‚

## ğŸ“š æ–‡æ¡£ç´¢å¼•

### ğŸ¯ æ¨èé˜…è¯»é¡ºåº

1. **[é«˜å±‚æ¶æ„](./qwen3_omni_highlevel.md)** â­ å…¥é—¨å¿…è¯»
   - ç®€æ´çš„ç»„ä»¶æ¦‚è§ˆ
   - ä¸»è¦æ•°æ®æµ
   - å…³é”®æŠ€æœ¯ç‚¹
   - **é€‚åˆ**: å¿«é€Ÿäº†è§£æ¨¡å‹æ•´ä½“ç»“æ„

2. **[å®Œæ•´æ¶æ„](./qwen3_omni_architecture.md)** â­â­ æ·±å…¥ç†è§£
   - è¯¦ç»†çš„æµç¨‹å›¾
   - å®Œæ•´çš„æ•°æ®æµè½¬
   - å„ç»„ä»¶è¯¦ç»†è§„æ ¼
   - **é€‚åˆ**: éœ€è¦å®ç°æˆ–ä¼˜åŒ–æ¨¡å‹

3. **[å±‚çº§ç»†èŠ‚](./qwen3_omni_layer_details.md)** â­â­â­ ä¸“å®¶çº§
   - å•å±‚å†…éƒ¨ç»“æ„
   - å…·ä½“æ“ä½œå’Œå…¬å¼
   - å‚æ•°é‡è®¡ç®—
   - å¤æ‚åº¦åˆ†æ
   - **é€‚åˆ**: æ·±åº¦ä¼˜åŒ–å’Œç ”ç©¶

### ğŸ“Š è‡ªåŠ¨ç”Ÿæˆçš„å›¾è¡¨

#### æŒ‰ç»„ä»¶åˆ†ç±»

- **[Thinker å®Œæ•´æ¦‚è§ˆ](./qwen3_omni_thinker_overall_mermaid.md)**
  - Thinker å…¨éƒ¨ 48 å±‚çš„å®Œæ•´ç»“æ„
  
- **[Thinker åŸºç¡€æ¨¡å‹](./qwen3_omni_thinker_mermaid.md)**
  - é MoE éƒ¨åˆ†çš„åŸºç¡€ç»“æ„
  
- **[Thinker MoE è¯¦è§£](./qwen3_omni_thinker_moe_mermaid.md)**
  - ä¸“å®¶æ··åˆå±‚çš„è¯¦ç»†ç»“æ„

- **[Talker å®Œæ•´æ¦‚è§ˆ](./qwen3_omni_talker_overall_mermaid.md)**
  - Talker å…¨éƒ¨ç»“æ„æ¦‚è§ˆ
  
- **[Talker è¯­è¨€æ¨¡å‹](./qwen3_omni_talker_lm_mermaid.md)**
  - Talker çš„ 48 å±‚ transformer
  
- **[Talker MoE](./qwen3_omni_talker_moe_mermaid.md)**
  - Talker ä¸­çš„ MoE å±‚
  
- **[Talker MTP](./qwen3_omni_talker_mtp_mermaid.md)**
  - Multi-Token Prediction (ç æœ¬é¢„æµ‹å™¨)

- **[Code2Wav å£°ç å™¨](./qwen3_omni_code2wav_mermaid.md)**
  - éŸ³é¢‘ç”Ÿæˆç½‘ç»œç»“æ„

#### åŸå§‹æ•°æ®

- **[å±‚è¯¦ç»†ä¿¡æ¯è¡¨](./qwen3_omni_layers.md)**
  - æ‰€æœ‰ 15,222 å±‚çš„è¯¦ç»†å‚æ•°
  - è¾“å…¥/è¾“å‡ºå½¢çŠ¶å’Œæ•°æ®ç±»å‹
  - Markdown è¡¨æ ¼æ ¼å¼

- **[åŸå§‹ JSON æ•°æ®](./qwen3_omni_data.json)**
  - æœºå™¨å¯è¯»çš„å®Œæ•´æ•°æ®
  - é€‚åˆç¨‹åºåˆ†æå’Œå¤„ç†

## ğŸ—ï¸ æ¨¡å‹æ¶æ„æ¦‚è§ˆ

```
Qwen3 Omni 30B
â”œâ”€â”€ Thinker (æ€ç»´æ¨¡å—) ~20B
â”‚   â”œâ”€â”€ Embedding Layer
â”‚   â”œâ”€â”€ 48 Ã— MoE Decoder Layer
â”‚   â”‚   â”œâ”€â”€ Self-Attention (GQA)
â”‚   â”‚   â””â”€â”€ Sparse MoE (128 experts)
â”‚   â””â”€â”€ LM Head
â”‚
â”œâ”€â”€ Text Projection (æ¡¥æ¥) ~10M
â”‚   â””â”€â”€ MLP (2048â†’1024)
â”‚
â”œâ”€â”€ Talker (è¯­éŸ³ç”Ÿæˆ) ~8B
â”‚   â”œâ”€â”€ Language Model (48 Ã— MoE Decoder)
â”‚   â””â”€â”€ Code Predictor (16 Ã— 5-layer)
â”‚       â””â”€â”€ 16 ä¸ªç‹¬ç«‹ç æœ¬é¢„æµ‹å™¨
â”‚
â””â”€â”€ Code2Wav (å£°ç å™¨) ~2B
    â”œâ”€â”€ Pre-Transformer (18 layers)
    â”œâ”€â”€ Post-Transformer (18 layers)
    â””â”€â”€ Wave Conv (ä¸Šé‡‡æ ·)
```

## ğŸ”‘ å…³é”®æŠ€æœ¯

### MoE (Mixture of Experts)
- **ä½ç½®**: Thinker å’Œ Talker çš„ MLP å±‚
- **ä¸“å®¶æ•°**: æ¯å±‚ 128 ä¸ª
- **æ¿€æ´»ç­–ç•¥**: Top-2 + 1 shared expert
- **ä¼˜åŠ¿**: å¤§å®¹é‡å‚æ•°,ä½è®¡ç®—æˆæœ¬

### RoPE (Rotary Position Embedding)
- **ä½œç”¨**: ä½ç½®ç¼–ç 
- **ä¼˜åŠ¿**: æ”¯æŒå¤–æ¨,é•¿åºåˆ—æ€§èƒ½å¥½

### GQA (Grouped Query Attention)
- **ç»“æ„**: Q 16 heads, K/V 4 heads
- **ä¼˜åŠ¿**: é™ä½ KV Cache å¤§å°

### RVQ (Residual Vector Quantization)
- **ç æœ¬æ•°**: 16 ä¸ª
- **ä½œç”¨**: éŸ³é¢‘å‹ç¼©è¡¨ç¤º
- **ä¼˜åŠ¿**: é«˜è´¨é‡,æ¸è¿›å¼ç»†åŒ–

### bfloat16
- **åº”ç”¨**: ä¸»è¦è®¡ç®—
- **ä¼˜åŠ¿**: æ˜¾å­˜å‡åŠ,é€Ÿåº¦æå‡

## ğŸ“ æ¨¡å‹è§„æ ¼

| ç»„ä»¶ | å±‚æ•° | éšè—ç»´åº¦ | å‚æ•°é‡ | MoE | æ•°æ®ç±»å‹ |
|------|------|----------|--------|-----|----------|
| **Thinker** | 48 | 2048 | ~20B | âœ… | bfloat16 |
| **Talker LM** | 48 | 1024 | ~7B | âœ… | bfloat16 |
| **Code Predictor** | 16Ã—5 | 1024 | ~1B | âŒ | bfloat16 |
| **Code2Wav** | 36 | 1024 | ~2B | âŒ | bf16â†’f32 |
| **æ€»è®¡** | - | - | **~30B** | - | - |

## ğŸµ æ•°æ®æµ

```
æ–‡æœ¬è¾“å…¥ (Token IDs)
    â†“ [B, L] int64
Thinker Embedding
    â†“ [B, L, 2048] bfloat16
Thinker Layers (48Ã—)
    â†“ [B, L, 2048] bfloat16
Text Projection
    â†“ [B, L, 1024] bfloat16
Talker LM (48Ã—)
    â†“ [B, L, 1024] bfloat16
Code Predictor (16Ã—)
    â†“ [B, 16, T] int64 (RVQ codes)
Code2Wav Embedding
    â†“ [B, 16, T, 1024] bfloat16
Pre+Post Transformer (36Ã—)
    â†“ [B, T, 1024] bfloat16
Wave Conv
    â†“ [B, audio_len] float32
éŸ³é¢‘è¾“å‡º
```

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### å¿«é€ŸæŸ¥çœ‹
```bash
# æŸ¥çœ‹é«˜å±‚æ¶æ„
cat qwen3_omni_highlevel.md

# æŸ¥çœ‹ç‰¹å®šç»„ä»¶
cat qwen3_omni_thinker_mermaid.md
```

### åœ¨ Markdown æŸ¥çœ‹å™¨ä¸­æ¸²æŸ“
æ”¯æŒ Mermaid çš„å·¥å…·:
- GitHub (è‡ªåŠ¨æ¸²æŸ“)
- VS Code (Markdown Preview Mermaid æ’ä»¶)
- Typora
- Obsidian
- GitLab

### ç¨‹åºåŒ–åˆ†æ
```python
import json

# è¯»å–åŸå§‹æ•°æ®
with open('qwen3_omni_data.json') as f:
    data = json.load(f)

# æŸ¥çœ‹æ€»è§ˆ
print(data['summary'])
# {'total_layers': 15222, 'total_hooks': 911}

# åˆ†æç‰¹å®šç»„ä»¶
thinker_layers = [
    layer for layer in data['layers']
    if layer['subcomponent'] == 'thinker'
]
print(f"Thinker layers: {len(thinker_layers)}")
```

## ğŸ”§ ç”Ÿæˆè¿™äº›æ–‡æ¡£

ä½¿ç”¨ `generate_model_structure.py` è„šæœ¬:

```bash
python generate_model_structure.py \
    --model_path /path/to/Qwen3-Omni-30B \
    --output_dir ./model_structure_output \
    --split_by_component \
    --max_edges 499 \
    --max_nodes 200 \
    --max_layer_depth 6
```

**å‚æ•°è¯´æ˜**:
- `--split_by_component`: æŒ‰ç»„ä»¶åˆ†åˆ«ç”Ÿæˆå›¾è¡¨
- `--max_edges 499`: æ¯ä¸ªå›¾æœ€å¤š 499 æ¡è¾¹
- `--max_nodes 200`: æ¯ä¸ªå›¾æœ€å¤š 200 ä¸ªèŠ‚ç‚¹
- `--max_layer_depth 6`: æœ€å¤§å±‚çº§æ·±åº¦
- `--no_compact`: ç¦ç”¨ç´§å‡‘æ¨¡å¼(æ˜¾ç¤ºå®Œæ•´åç§°)

## ğŸ“– ç›¸å…³èµ„æº

### å®˜æ–¹èµ„æº
- [Qwen3-Omni æŠ€æœ¯æŠ¥å‘Š](https://arxiv.org/abs/2024.xxxxx)
- [Hugging Face æ¨¡å‹](https://huggingface.co/Qwen/Qwen3-Omni-30B-A3B-Thinking)
- [GitHub ä»“åº“](https://github.com/QwenLM/Qwen3-Omni)

### å‚è€ƒè®ºæ–‡
- **MoE**: [Switch Transformers](https://arxiv.org/abs/2101.03961)
- **RoPE**: [RoFormer](https://arxiv.org/abs/2104.09864)
- **GQA**: [GQA: Training Generalized Multi-Query Transformer](https://arxiv.org/abs/2305.13245)
- **RVQ**: [SoundStream](https://arxiv.org/abs/2107.03312)

## ğŸ¤ è´¡çŒ®

è¿™äº›æ–‡æ¡£æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„,å¦‚æœå‘ç°é”™è¯¯æˆ–æœ‰æ”¹è¿›å»ºè®®:

1. ä¿®æ”¹ `qwen3_omni_moe_transformers.py` ä¸­çš„ tracing é€»è¾‘
2. ä¿®æ”¹ `generate_model_structure.py` ä¸­çš„ç”Ÿæˆé€»è¾‘
3. é‡æ–°è¿è¡Œç”Ÿæˆè„šæœ¬

## ğŸ“ æ›´æ–°æ—¥å¿—

- **2026-01-09**: åˆå§‹ç‰ˆæœ¬
  - åˆ›å»ºå®Œæ•´æ¶æ„æ–‡æ¡£
  - æ·»åŠ é«˜å±‚æ¦‚è§ˆ
  - æ·»åŠ å±‚çº§ç»†èŠ‚åˆ†æ
  - æŒ‰ç»„ä»¶åˆ†ç±»ç”Ÿæˆå›¾è¡¨

---

**æ¨¡å‹**: Qwen3-Omni-30B-A3B-Thinking  
**ç”Ÿæˆæ—¶é—´**: 2026-01-09  
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
